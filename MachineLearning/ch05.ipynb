{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5장 딥러닝과 텐서플로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 텐서플로와 넘파이의 호환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#프로그램 5-1 텐서플로 버전과 동작 확인 \n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "a = tf.random.uniform([2,3], 0,1)\n",
    "print(a)\n",
    "print(type(a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#프로그램 5-2 tensorflow와 numpy의 호환\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "t = tf.random.uniform([2,3],0,1)\n",
    "n = np.random.uniform(0,1,[2,3])\n",
    "print(\"tensorflow로 생성한 텐서:\\n\",t,\"\\n\")\n",
    "print(\"numpy로 생성한 ndarray:\\n\",n,\"\\n\")\n",
    "\n",
    "res = t + n \n",
    "print(\"덧셈 결과:\\n\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#프로그램 5-4 텐서플로 프로그래밍\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# OR 데이터 구축\n",
    "x = [[0.0,0.0],[0.0,1.0],[1.0,0.0],[1.0,1.0]]\n",
    "y = [[-1],[1],[1],[1]]\n",
    "\n",
    "# 그림 4-3의 퍼셉트론\n",
    "w = tf.Variable([[1.0],[1.0]])\n",
    "b = tf.Variable(-0.5)\n",
    "\n",
    "# 식 4.3의 퍼셉트론 동작\n",
    "s = tf.add(tf.matmul(x,w), b)\n",
    "o = tf.sign(s)\n",
    "\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#프로그램 5-5 텐서플로 프로그래밍: 퍼셉트론 학습\n",
    "import tensorflow as tf\n",
    "\n",
    "# OR 데이터 구축\n",
    "x = [[0.0,0.0],[0.0,1.0],[1.0,0.0],[1.0,1.0]]\n",
    "y = [[-1],[1],[1],[1]]\n",
    "\n",
    "# 가중치 초기화\n",
    "w = tf.Variable(tf.random.uniform([2,1], -0.5, 0.5))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# 옵티마이저\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "# 전방 계산 (식4.3)\n",
    "def forward():\n",
    "    s = tf.add(tf.matmul(x,w),b)\n",
    "    o = tf.tanh(s)\n",
    "    return o\n",
    "\n",
    "# 손실 함수 정의\n",
    "def loss():\n",
    "    o = forward()\n",
    "    return tf.reduce_mean((y-o)**2)\n",
    "\n",
    "# 500세대까지 학습 (100세대마다 학습 정보 출력)\n",
    "for i in range(500):\n",
    "    opt.minimize(loss, var_list=[w,b])\n",
    "    if(i % 100 == 0): print('loss at epoch', i, '=', loss().numpy())\n",
    "\n",
    "# 학습된 퍼셉트론으로 OR 데이터를 예측\n",
    "o = forward()\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#프로그램 5-6 케라스 프로그래밍\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# OR 데이터 구축\n",
    "x = [[0.0,0.0],[0.0,1.0],[1.0,0.0],[1.0,1.0]]\n",
    "y = [[-1],[1],[1],[1]]\n",
    "\n",
    "n_input = 2\n",
    "n_output = 1\n",
    "\n",
    "perceptron = Sequential()\n",
    "perceptron.add(Dense(units=n_output, activation='tanh',\n",
    "input_shape=(n_input,),kernel_initializer='random_uniform',\n",
    "bias_initializer='zeros'))\n",
    "\n",
    "perceptron.compile(loss='mse', optimizer=SGD\n",
    "(learning_rate = 0.1), metrics=['mse'])\n",
    "perceptron.fit(x,y,epochs=500,verbose=2)\n",
    "\n",
    "res = perceptron.predict(x)\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로그램 5-7 (a) 텐서플로 프로그래밍: 다층 퍼셉트론으로 MINIST 인식\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# MINIST 읽어 와서 신경망에 입력할 형태로 변환\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)       # 텐서 모양 변환\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype(np.float32)/255.0  # ndarray로 변환\n",
    "x_test = x_test.astype(np.float32)/255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)    # 원핫 코드로 변환\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "n_input = 784\n",
    "n_hidden = 1024\n",
    "n_output = 10\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=n_hidden, activation='tanh', input_shape=(n_input,),\n",
    "kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "mlp.add(Dense(units=n_output, activation = 'tanh', \n",
    "kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "\n",
    "mlp.compile(loss = 'mean_squared_error', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "hist=mlp.fit(x_train, y_train, batch_size=128, epochs=30, validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "res = mlp.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"정확률은\", res[1]*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로그램 5-7 (b) 텐서플로 프로그래밍: 다층 퍼셉트론으로 MNIST 인식 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 정확률 곡선\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc = 'upper left')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 손실 함수 곡선\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#프로그램 5-8 텐서플로 프로그래밍: 다층 퍼셉트론으로 fashion MNIST 인식\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# fashion MNIST 데이터셋을 읽어와 신경망에 입력할 형태로 변환\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)       # 텐서 모양 변환\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype(np.float32)/255.0  # ndarray로 변환\n",
    "x_test = x_test.astype(np.float32)/255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)    # 원핫 코드로 변환\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "n_input = 784\n",
    "n_hidden = 1024\n",
    "n_output = 10\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=n_hidden, activation='tanh', input_shape=(n_input,),\n",
    "kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "mlp.add(Dense(units=n_output, activation = 'tanh', \n",
    "kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "\n",
    "mlp.compile(loss = 'mean_squared_error', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "hist=mlp.fit(x_train, y_train, batch_size=128, epochs=30, validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "res = mlp.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"정확률은\", res[1]*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#프로그램 5-9 같은 다층 퍼셉트론으로 MNIST 인식\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# MNIST 읽어 와서 신경망에 입력할 형태로 변환\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)       # 텐서 모양 변환\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype(np.float32) / 255.0       #ndarray로 변환\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)    # 원핫 코드로 변환 \n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# 신경망 구조 설정 \n",
    "n_input = 784\n",
    "n_hidden1 = 1024\n",
    "n_hidden2 = 512\n",
    "n_hidden3 = 512\n",
    "n_hidden4 = 512 \n",
    "n_output = 10\n",
    "\n",
    "# 신경망 구조 설계 \n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=n_hidden1, activation='tanh', input_shape=(n_input,), \n",
    "kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "mlp.add(Dense(units=n_hidden2, activation='tanh',\n",
    "kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "mlp.add(Dense(units=n_hidden3, activation='tanh',\n",
    "kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "mlp.add(Dense(units=n_hidden4, activation='tanh', \n",
    "kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "mlp.add(Dense(units=n_output, activation='tanh', \n",
    "kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "\n",
    "# 신경망 학습 \n",
    "mlp.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "hist = mlp.fit(x_train, y_train, batch_size=128, epochs=30, validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "# 신경망의 정확률 측정 \n",
    "res = mlp.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"정확률은\", res[1]*100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 정확률 곡선 \n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 손실 함수 곡선 \n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adagrad, RMSprop\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 시작 직전 시각을 기록\n",
    "start = time.time()\n",
    "# fashion MNIST 데이터셋을 읽어와 신경망에 입력할 형태로 변환\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)       # 텐서 모양 변환\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype(np.float32)/255.0  # ndarray로 변환\n",
    "x_test = x_test.astype(np.float32)/255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)    # 원핫 코드로 변환\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "n_input = 784\n",
    "n_hidden1 = 1024\n",
    "n_hidden2 = 512 \n",
    "n_hidden3 = 512\n",
    "n_hidden4 = 512\n",
    "n_output = 10 \n",
    "\n",
    "# 하이퍼 매개변수 설정 \n",
    "batch_siz = 256\n",
    "n_epoch = 20\n",
    "k = 5  # 5-겹 \n",
    "\n",
    "# 모델을 설계해주는 함수(모델을 나타내는 객체 model을 반환)\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = n_hidden1, activation = 'relu', input_shape=(n_input,)))\n",
    "    model.add(Dense(units = n_hidden2, activation = 'relu'))\n",
    "    model.add(Dense(units = n_hidden3, activation = 'relu'))\n",
    "    model.add(Dense(units = n_hidden4, activation = 'relu'))\n",
    "    model.add(Dense(units = n_output, activation = 'softmax'))\n",
    "    return model\n",
    "\n",
    "# 교차 검증을 해주는 함수 (서로 다른 옵티마이저(opt)에 대해)\n",
    "def cross_validation(opt):\n",
    "    accuracy = []\n",
    "    for train_index, val_index in KFold(k).split(x_train):\n",
    "        xtrain, xval = x_train[train_index], x_train[val_index]\n",
    "        ytrain, yval = y_train[train_index], y_train[val_index]\n",
    "        dmlp = build_model()\n",
    "        dmlp.compile(loss='categorical_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
    "        dmlp.fit(xtrain, ytrain, batch_size = batch_siz, epochs=n_epoch, verbose = 0)\n",
    "        accuracy.append(dmlp.evaluate(xval, yval, verbose = 0)[1])\n",
    "    return accuracy\n",
    "\n",
    "# 옵티마이저 4개에 대해 교차 검증을 실행\n",
    "acc_sgd = cross_validation(SGD())\n",
    "acc_adam = cross_validation(Adam())\n",
    "acc_adagrad = cross_validation(Adagrad())\n",
    "acc_rmsprop = cross_validation(RMSprop())\n",
    "\n",
    "# 옵티마이저 4개의 정확률을 비교\n",
    "print(\"SGD:\", np.array(acc_sgd).mean())\n",
    "print(\"Adam:\", np.array(acc_adam).mean())\n",
    "print(\"Adagrad:\", np.array(acc_adagrad).mean())\n",
    "print(\"RMSprop:\", np.array(acc_rmsprop).mean())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 네 옵티마이저의 정확률은 박스플롯으로 비교\n",
    "plt.boxplot([acc_sgd, acc_adam, acc_adagrad, acc_rmsprop], labels=[\"SGD\", \"Adam\", \"Adagrad\", \"RMSprop\"])\n",
    "plt.grid()\n",
    "\n",
    "# 끝난 직후 시간을 기록\n",
    "end = time.time()\n",
    "# 시간 차이를 계산하여 출력\n",
    "print('소요 시간은 ', end-start, '초입니다.')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('sein')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87b108159bdca7fa0cfb159cd335e90af3d948be4608d83055d1a3ade1b82071"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
